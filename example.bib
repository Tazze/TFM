@misc{wiki:Lanczos,
    author = "{Wikipedia contributors}",
    title = "Lanczos resampling --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2019",
    url = {https://en.wikipedia.org/w/index.php?title=Lanczos_resampling&oldid=887426730},
    note = "[Online; accessed 8-April-2019]"
}
 
@misc{PNG,
	series =	{Request for Comments},
	number =	2083,
	howpublished =	{RFC 2083},
	publisher =	{RFC Editor},
	doi =		{10.17487/RFC2083},
	url =		{https://rfc-editor.org/rfc/rfc2083.txt},
        author =	{Thomas Boutell},
	title =		{{PNG (Portable Network Graphics) Specification Version 1.0}},
	pagetotal =	102,
	year =		1997,
	month =		mar,
	abstract =	{This document describes PNG (Portable Network Graphics), an extensible file format for the lossless, portable, well-compressed storage of raster images. This memo provides information for the Internet community. This memo does not specify an Internet standard of any kind.},
}

@techreport{JPEG,
  added-at = {2007-01-19T01:55:57.000+0100},
  address = {Milpitas, CA, USA},
  author = {Hamilton, Eric},
  biburl = {https://www.bibsonomy.org/bibtex/298c74135f2ed5b71d04c54be9c64677c/timo},
  day = 1,
  institution = {C-Cube Microsystems},
  interhash = {a944d9c3a543ed2922df292fa4d66701},
  intrahash = {98c74135f2ed5b71d04c54be9c64677c},
  keywords = {file JFIF format JPEG},
  month = {9},
  timestamp = {2007-01-19T01:55:57.000+0100},
  title = {JPEG File Interchange Format},
  url = {http://www.w3.org/Graphics/JPEG/jfif3.pdf},
  year = 1992
}

@ARTICLE{BM3D-Net, 
author={D. {Yang} and J. {Sun}}, 
journal={IEEE Signal Processing Letters}, 
title={BM3D-Net: A Convolutional Neural Network for Transform-Domain Collaborative Filtering}, 
year={2018}, 
volume={25}, 
number={1}, 
pages={55-59}, 
abstract={Denoising is a fundamental task in image processing with wide applications for enhancing image qualities. BM3D is considered as an effective baseline for image denoising. Although learning-based methods have been dominant in this area recently, the traditional methods are still valuable to inspire new ideas by combining with learning-based approaches. In this letter, we propose a new convolutional neural network inspired by the classical BM3D algorithm, dubbed as BM3D-Net. We unroll the computational pipeline of BM3D algorithm into a convolutional neural network structure, with “extraction” and “aggregation” layers to model block matching stage in BM3D. We apply our network to three denoising tasks: gray-scale image denoising, color image denoising, and depth map denoising. Experiments show that BM3D-Net significantly outperforms the basic BM3D method, and achieves competitive results compared with state of the art on these tasks.}, 
keywords={collaborative filtering;feedforward neural nets;grey systems;image colour analysis;image denoising;image matching;learning (artificial intelligence);transforms;convolutional neural network structure;gray-scale image denoising;color image denoising;basic BM3D;BM3D-Net;transform-domain collaborative filtering;image processing;extraction layer;aggregation layer;block matching;depth map denoising;Convolution;Image denoising;Wavelet transforms;Noise reduction;Neural networks;Three-dimensional displays;BM3D;convolutional neural networks;denoising;nonlocal methods}, 
doi={10.1109/LSP.2017.2768660}, 
ISSN={1070-9908}, 
month={Jan},}

@misc{waifu2x,
  author = {nagadomi},
  title = {waifu2x},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/nagadomi/waifu2x}},
  commit = {7d156917ae1113ab847dab15c75db7642231e7fa}
}

@misc{waifu2x-caffe,
  author = {lltcggie},
  title = {waifu2x-caffe},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/lltcggie/waifu2x-caffe}},
  commit = {3f26c040f2c1b17894f2ef1766c4cd1419f9f7ae}
}

@misc{cntk-tutorial,
author  = {Borna Vukorepa},
title   = {CNTK 302 Part B: Image super-resolution using CNNs and GANs},
url     = {https://cntk.ai/pythondocs/CNTK_302B_Image_Super-resolution_Using_CNNs_and_GANs.html},
year    = {2017},
month   = {October}
}

@misc{cntk,
  author = {Microsoft},
  title = {CNTK},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Microsoft/CNTK}},
  commit = {9688ac6aea6e670a3136abc2132705ffc5a427de}
}

@misc{theano,
  author = {Theano},
  title = {Theano},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Theano/Theano}},
  commit = {9feed78682c9f18754345ef9ed6cda5b89de2434}
}

@misc{pytorch,
  author = {pytorch},
  title = {pytorch},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/pytorch/pytorch}},
  commit = {23b0908d3852973de1a1f3dbd117ebabdf51153e}
}

@misc{tensorflow,
  author = {tensorflow},
  title = {tensorflow},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tensorflow/tensorflow}},
  commit = {7eb01e15d0f2700851697c99cfafcfdbc5bf3323}
}

@ARTICLE{BM3D, 
author={K. {Dabov} and A. {Foi} and V. {Katkovnik} and K. {Egiazarian}}, 
journal={IEEE Transactions on Image Processing}, 
title={Image Denoising by Sparse 3-D Transform-Domain Collaborative Filtering}, 
year={2007}, 
volume={16}, 
number={8}, 
pages={2080-2095}, 
keywords={image colour analysis;image denoising;image enhancement;image representation;Wiener filters;image denoising;3D transform-domain collaborative filter;sparse representation;image fragment;image enhancement;Wiener filter;Image denoising;Collaboration;Filtering;Noise reduction;Signal processing algorithms;Signal processing;Energy resolution;Spatial resolution;Signal resolution;Discrete cosine transforms;Adaptive grouping;block matching;image denoising;sparsity;3-D transform shrinkage;Algorithms;Artifacts;Image Enhancement;Image Interpretation, Computer-Assisted;Imaging, Three-Dimensional;Reproducibility of Results;Sensitivity and Specificity}, 
doi={10.1109/TIP.2007.901238}, 
ISSN={1057-7149}, 
month={Aug},}

@ARTICLE{SC, 
author={J. {Yang} and J. {Wright} and T. S. {Huang} and Y. {Ma}}, 
journal={IEEE Transactions on Image Processing}, 
title={Image Super-Resolution Via Sparse Representation}, 
year={2010}, 
volume={19}, 
number={11}, 
pages={2861-2873}, 
abstract={This paper presents a new approach to single-image superresolution, based upon sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low-resolution and high-resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low-resolution image patch can be applied with the high-resolution image patch dictionary to generate a high-resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs , reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution (SR) and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle SR with noisy inputs in a more unified framework.}, 
keywords={dictionaries;image reconstruction;image resolution;matrix decomposition;statistical analysis;single-image superresolution;sparse signal representation;image statistics;compressed sensing;image patch dictionary;nonnegative matrix factorization;super-resolution image reconstruction;Image resolution;Signal resolution;Dictionaries;Signal representations;Statistics;Compressed sensing;Computational efficiency;Image generation;Strontium;Noise robustness;Face hallucination;image super-resolution (SR);nonnegative matrix factorization;sparse coding;sparse representation}, 
doi={10.1109/TIP.2010.2050625}, 
ISSN={1057-7149}, 
month={Nov},}

@INPROCEEDINGS{MLP-BM3D, 
author={H. C. {Burger} and C. J. {Schuler} and S. {Harmeling}}, 
booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
title={Image denoising: Can plain neural networks compete with BM3D?}, 
year={2012}, 
volume={}, 
number={}, 
pages={2392-2399}, 
abstract={Image denoising can be described as the problem of mapping from a noisy image to a noise-free image. The best currently available denoising methods approximate this mapping with cleverly engineered algorithms. In this work we attempt to learn this mapping directly with a plain multi layer perceptron (MLP) applied to image patches. While this has been done before, we will show that by training on large image databases we are able to compete with the current state-of-the-art image denoising methods. Furthermore, our approach is easily adapted to less extensively studied types of noise (by merely exchanging the training data), for which we achieve excellent results as well.}, 
keywords={image denoising;learning (artificial intelligence);neural nets;image denoising;neural networks;BM3D;noisy image mapping;noise-free image;mapping approximation;multi layer perceptron;MLP;image patches;training;large image databases;Noise;Training;Noise measurement;Noise level;Noise reduction;Neural networks;Standards}, 
doi={10.1109/CVPR.2012.6247952}, 
ISSN={1063-6919}, 
month={June},}

@INPROCEEDINGS{ANR, 
author={R. {Timofte} and V. {De} and L. V. {Gool}}, 
booktitle={2013 IEEE International Conference on Computer Vision}, 
title={Anchored Neighborhood Regression for Fast Example-Based Super-Resolution}, 
year={2013}, 
volume={}, 
number={}, 
pages={1920-1927}, 
abstract={Recently there have been significant advances in image up scaling or image super-resolution based on a dictionary of low and high resolution exemplars. The running time of the methods is often ignored despite the fact that it is a critical factor for real applications. This paper proposes fast super-resolution methods while making no compromise on quality. First, we support the use of sparse learned dictionaries in combination with neighbor embedding methods. In this case, the nearest neighbors are computed using the correlation with the dictionary atoms rather than the Euclidean distance. Moreover, we show that most of the current approaches reach top performance for the right parameters. Second, we show that using global collaborative coding has considerable speed advantages, reducing the super-resolution mapping to a precomputed projective matrix. Third, we propose the anchored neighborhood regression. That is to anchor the neighborhood embedding of a low resolution patch to the nearest atom in the dictionary and to precompute the corresponding embedding matrix. These proposals are contrasted with current state-of-the-art methods on standard images. We obtain similar or improved quality and one or two orders of magnitude speed improvements.}, 
keywords={image coding;image reconstruction;image resolution;neighborhood regression;fast example-based super-resolution;image upscaling;image super-resolution;sparse learned dictionaries;collaborative coding;super-resolution mapping reduction;Dictionaries;Image resolution;PSNR;Encoding;Training;Signal resolution;Interpolation;super-resolution;neighbor embedding;sparse coding;ridge regression;anchored neighborhood regression}, 
doi={10.1109/ICCV.2013.241}, 
ISSN={1550-5499}, 
month={Dec},}

@INPROCEEDINGS{BPJDL, 
author={L. {He} and H. {Qi} and R. {Zaretzki}}, 
booktitle={2013 IEEE Conference on Computer Vision and Pattern Recognition}, 
title={Beta Process Joint Dictionary Learning for Coupled Feature Spaces with Application to Single Image Super-Resolution}, 
year={2013}, 
volume={}, 
number={}, 
pages={345-352}, 
abstract={This paper addresses the problem of learning over-complete dictionaries for the coupled feature spaces, where the learned dictionaries also reflect the relationship between the two spaces. A Bayesian method using a beta process prior is applied to learn the over-complete dictionaries. Compared to previous couple feature spaces dictionary learning algorithms, our algorithm not only provides dictionaries that customized to each feature space, but also adds more consistent and accurate mapping between the two feature spaces. This is due to the unique property of the beta process model that the sparse representation can be decomposed to values and dictionary atom indicators. The proposed algorithm is able to learn sparse representations that correspond to the same dictionary atoms with the same sparsity but different values in coupled feature spaces, thus bringing consistent and accurate mapping between coupled feature spaces. Another advantage of the proposed method is that the number of dictionary atoms and their relative importance may be inferred non-parametrically. We compare the proposed approach to several state-of-the-art dictionary learning methods by applying this method to single image super-resolution. The experimental results show that dictionaries learned by our method produces the best super-resolution results compared to other state-of-the-art methods.}, 
keywords={Bayes methods;feature extraction;image representation;image resolution;learning (artificial intelligence);beta process joint dictionary learning;coupled feature spaces;single image superresolution;over-complete dictionaries learning;Bayesian method;beta process prior;feature space mapping;beta process model;sparse representation decomposition;dictionary atom indicators;sparse representation learning;Dictionaries;Image resolution;Signal resolution;Encoding;Image reconstruction;Vectors;Joints;Dictionary Learning;Beta Process;Image Super-Resolution;Coupled Feature Spaces}, 
doi={10.1109/CVPR.2013.51}, 
ISSN={1063-6919}, 
month={June},}

@InProceedings{APlus,
author="Timofte, Radu
and De Smet, Vincent
and Van Gool, Luc",
editor="Cremers, Daniel
and Reid, Ian
and Saito, Hideo
and Yang, Ming-Hsuan",
title="A+: Adjusted Anchored Neighborhood Regression for Fast Super-Resolution",
booktitle="Computer Vision -- ACCV 2014",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="111--126",
abstract="We address the problem of image upscaling in the form of single image super-resolution based on a dictionary of low- and high-resolution exemplars. Two recently proposed methods, Anchored Neighborhood Regression (ANR) and Simple Functions (SF), provide state-of-the-art quality performance. Moreover, ANR is among the fastest known super-resolution methods. ANR learns sparse dictionaries and regressors anchored to the dictionary atoms. SF relies on clusters and corresponding learned functions. We propose A+, an improved variant of ANR, which combines the best qualities of ANR and SF. A+ builds on the features and anchored regressors from ANR but instead of learning the regressors on the dictionary it uses the full training material, similar to SF. We validate our method on standard images and compare with state-of-the-art methods. We obtain improved quality (i.e. 0.2--0.7 dB PSNR better than ANR) and excellent time complexity, rendering A+ the most efficient dictionary-based super-resolution method to date.",
isbn="978-3-319-16817-3"
}

@INPROCEEDINGS{CSCN, 
author={Z. {Wang} and D. {Liu} and J. {Yang} and W. {Han} and T. {Huang}}, 
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
title={Deep Networks for Image Super-Resolution with Sparse Prior}, 
year={2015}, 
volume={}, 
number={}, 
pages={370-378}, 
abstract={Deep learning techniques have been successfully applied in many areas of computer vision, including low-level image restoration problems. For image super-resolution, several models based on deep neural networks have been recently proposed and attained superior performance that overshadows all previous handcrafted models. The question then arises whether large-capacity and data-driven models have become the dominant solution to the ill-posed super-resolution problem. In this paper, we argue that domain expertise represented by the conventional sparse coding model is still valuable, and it can be combined with the key ingredients of deep learning to achieve further improved results. We show that a sparse coding model particularly designed for super-resolution can be incarnated as a neural network, and trained in a cascaded structure from end to end. The interpretation of the network based on sparse coding leads to much more efficient and effective training, as well as a reduced model size. Our model is evaluated on a wide range of images, and shows clear advantage over existing state-of-the-art methods in terms of both restoration accuracy and human subjective quality.}, 
keywords={computer vision;image resolution;learning (artificial intelligence);neural nets;image superresolution;deep learning techniques;computer vision;low-level image restoration problems;deep neural networks;data-driven models;sparse coding model;restoration accuracy;human subjective quality;Encoding;Training;Image coding;Machine learning;Neural networks;Dictionaries;Neurons}, 
doi={10.1109/ICCV.2015.50}, 
ISSN={2380-7504}, 
month={Dec},}

@article{DJSR,
  author    = {Zhangyang Wang and
               Yingzhen Yang and
               Zhaowen Wang and
               Shiyu Chang and
               Wei Han and
               Jianchao Yang and
               Thomas S. Huang},
  title     = {Self-Tuned Deep Super Resolution},
  journal   = {CoRR},
  volume    = {abs/1504.05632},
  year      = {2015},
  url       = {http://arxiv.org/abs/1504.05632},
  archivePrefix = {arXiv},
  eprint    = {1504.05632},
  timestamp = {Wed, 15 Aug 2018 12:55:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/WangYWCHYH15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{IA,
  author    = {Radu Timofte and
               Rasmus Rothe and
               Luc J. Van Gool},
  title     = {Seven ways to improve example-based single image super resolution},
  journal   = {CoRR},
  volume    = {abs/1511.02228},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.02228},
  archivePrefix = {arXiv},
  eprint    = {1511.02228},
  timestamp = {Mon, 13 Aug 2018 16:47:18 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/TimofteRG15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{NBSRF, 
author={J. {Salvador} and E. {Pérez-Pellitero}}, 
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
title={Naive Bayes Super-Resolution Forest}, 
year={2015}, 
volume={}, 
number={}, 
pages={325-333}, 
abstract={This paper presents a fast, high-performance method for super resolution with external learning. The first contribution leading to the excellent performance is a bimodal tree for clustering, which successfully exploits the antipodal invariance of the coarse-to-high-res mapping of natural image patches and provides scalability to finer partitions of the underlying coarse patch space. During training an ensemble of such bimodal trees is computed, providing different linearizations of the mapping. The second and main contribution is a fast inference algorithm, which selects the most suitable mapping function within the tree ensemble for each patch by adopting a Local Naive Bayes formulation. The experimental validation shows promising scalability properties that reflect the suitability of the proposed model, which may also be generalized to other tasks. The resulting method is beyond one order of magnitude faster and performs objectively and subjectively better than the current state of the art.}, 
keywords={Bayes methods;image resolution;inference mechanisms;learning (artificial intelligence);trees (mathematics);mapping function;inference algorithm;bimodal tree;external learning;naive Bayes superresolution forest;Image resolution;Training;Image reconstruction;Manifolds;Vegetation;Dictionaries;Principal component analysis}, 
doi={10.1109/ICCV.2015.45}, 
ISSN={2380-7504}, 
month={Dec},}

@article{ResNet,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Mon, 13 Aug 2018 16:46:56 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{RFL, 
author={S. {Schulter} and C. {Leistner} and H. {Bischof}}, 
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Fast and accurate image upscaling with super-resolution forests}, 
year={2015}, 
volume={}, 
number={}, 
pages={3791-3799}, 
abstract={The aim of single image super-resolution is to reconstruct a high-resolution image from a single low-resolution input. Although the task is ill-posed it can be seen as finding a non-linear mapping from a low to high-dimensional space. Recent methods that rely on both neighborhood embedding and sparse-coding have led to tremendous quality improvements. Yet, many of the previous approaches are hard to apply in practice because they are either too slow or demand tedious parameter tweaks. In this paper, we propose to directly map from low to high-resolution patches using random forests. We show the close relation of previous work on single image super-resolution to locally linear regression and demonstrate how random forests nicely fit into this framework. During training the trees, we optimize a novel and effective regularized objective that not only operates on the output space but also on the input space, which especially suits the regression task. During inference, our method comprises the same well-known computational efficiency that has made random forests popular for many computer vision problems. In the experimental part, we demonstrate on standard benchmarks for single image super-resolution that our approach yields highly accurate state-of-the-art results, while being fast in both training and evaluation.}, 
keywords={computer vision;image coding;image reconstruction;image resolution;random processes;regression analysis;image upscaling;superresolution forests;single image superresolution;high-resolution image reconstruction;nonlinear mapping;neighborhood embedding;sparse-coding;random forests;locally linear regression;computer vision problems;Image resolution;Dictionaries;Training;Vegetation;Encoding;Yttrium;Computer vision}, 
doi={10.1109/CVPR.2015.7299003}, 
ISSN={1063-6919}, 
month={June},}

@INPROCEEDINGS{SelfEx, 
author={J. {Huang} and A. {Singh} and N. {Ahuja}}, 
booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Single image super-resolution from transformed self-exemplars}, 
year={2015}, 
volume={}, 
number={}, 
pages={5197-5206}, 
abstract={Self-similarity based super-resolution (SR) algorithms are able to produce visually pleasing results without extensive training on external databases. Such algorithms exploit the statistical prior that patches in a natural image tend to recur within and across scales of the same image. However, the internal dictionary obtained from the given image may not always be sufficiently expressive to cover the textural appearance variations in the scene. In this paper, we extend self-similarity based SR to overcome this drawback. We expand the internal patch search space by allowing geometric variations. We do so by explicitly localizing planes in the scene and using the detected perspective geometry to guide the patch search process. We also incorporate additional affine transformations to accommodate local shape variations. We propose a compositional model to simultaneously handle both types of transformations. We extensively evaluate the performance in both urban and natural scenes. Even without using any external training databases, we achieve significantly superior results on urban scenes, while maintaining comparable performance on natural scenes as other state-of-the-art SR algorithms.}, 
keywords={geometry;image resolution;statistical analysis;single image super-resolution;self-similarity based super-resolution algorithms;statistical prior;internal dictionary;self-similarity based SR algorithm;geometric variations;patch search process;local shape variations;Training;Transmission line matrix methods;Databases;Dictionaries;Image resolution;Shape;Estimation}, 
doi={10.1109/CVPR.2015.7299156}, 
ISSN={1063-6919}, 
month={June},}

@ARTICLE{SRCNN, 
author={C. {Dong} and C. C. {Loy} and K. {He} and X. {Tang}}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Image Super-Resolution Using Deep Convolutional Networks}, 
year={2016}, 
volume={38}, 
number={2}, 
pages={295-307}, 
abstract={We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.}, 
keywords={convolution;image resolution;image restoration;learning (artificial intelligence);neural nets;image super-resolution;deep learning method;end-to-end mapping;CNN;low-resolution image;color channel;deep convolutional neural network;reconstruction quality;sparse-coding;image restoration;Image resolution;Neural networks;Image reconstruction;Convolutional codes;Feature extraction;Training;Super-resolution;deep convolutional neural networks;sparse coding;Super-resolution;deep convolutional neural networks;sparse coding}, 
doi={10.1109/TPAMI.2015.2439281}, 
ISSN={0162-8828}, 
month={Feb},}

@ARTICLE{DnCNN, 
author={K. {Zhang} and W. {Zuo} and Y. {Chen} and D. {Meng} and L. {Zhang}}, 
journal={IEEE Transactions on Image Processing}, 
title={Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising}, 
year={2017}, 
volume={26}, 
number={7}, 
pages={3142-3155}, 
abstract={The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden layers. This property motivates us to train a single DnCNN model to tackle with several general image denoising tasks, such as Gaussian denoising, single image super-resolution, and JPEG image deblocking. Our extensive experiments demonstrate that our DnCNN model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from GPU computing.}, 
keywords={AWGN;feedforward neural nets;Gaussian processes;image denoising;learning (artificial intelligence);neural net architecture;Gaussian denoiser;deep CNN;image denoising;discriminative model learning;feedforward denoising convolutional neural networks;regularization method;learning algorithm;very deep architecture;batch normalization;training process;discriminative denoising models;additive white Gaussian noise;DnCNN model;unknown noise level;residual learning strategy;single image super-resolution;JPEG image deblocking;GPU computing;Noise reduction;Image denoising;Training;Computational modeling;Noise level;Neural networks;Transform coding;Image denoising;convolutional neural networks;residual learning;batch normalization}, 
doi={10.1109/TIP.2017.2662206}, 
ISSN={1057-7149}, 
month={July},}

@article{DRCN,
  author    = {Jiwon Kim and
               Jung Kwon Lee and
               Kyoung Mu Lee},
  title     = {Deeply-Recursive Convolutional Network for Image Super-Resolution},
  journal   = {CoRR},
  volume    = {abs/1511.04491},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.04491},
  archivePrefix = {arXiv},
  eprint    = {1511.04491},
  timestamp = {Mon, 13 Aug 2018 16:48:16 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KimLL15a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ESPCN,
  author    = {Wenzhe Shi and
               Jose Caballero and
               Ferenc Husz{\'{a}}r and
               Johannes Totz and
               Andrew P. Aitken and
               Rob Bishop and
               Daniel Rueckert and
               Zehan Wang},
  title     = {Real-Time Single Image and Video Super-Resolution Using an Efficient
               Sub-Pixel Convolutional Neural Network},
  journal   = {CoRR},
  volume    = {abs/1609.05158},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.05158},
  archivePrefix = {arXiv},
  eprint    = {1609.05158},
  timestamp = {Mon, 13 Aug 2018 16:47:09 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ShiCHTABRW16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{FSRCNN,
  author    = {Chao Dong and
               Chen Change Loy and
               Xiaoou Tang},
  title     = {Accelerating the Super-Resolution Convolutional Neural Network},
  journal   = {CoRR},
  volume    = {abs/1608.00367},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.00367},
  archivePrefix = {arXiv},
  eprint    = {1608.00367},
  timestamp = {Mon, 13 Aug 2018 16:47:56 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/DongLT16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@conference {PSyCo,
	title = {PSyCo: Manifold Span Reduction for Super Resolution},
	booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
	year = {2016},
	month = {06/2016},
	address = {Las Vegas, Nevada, USA},
	abstract = {<p>\&nbsp;</p><p><img src="/web/sites/default/files/users/jrh/2016_CVPR.png" width="600" height="409" /></p><p>T<span style="font-size: 13.008px; line-height: 1.538em;">he main challenge in Super Resolution (SR) is to discover the mapping between the low- and high-resolution manifolds of image patches, a complex ill-posed problem which has recently been addressed through piecewise linear regression with promising results. In this paper we present a novel regression-based SR algorithm that benefits from an extended knowledge of the structure of both manifolds. We propose a transform that collapses the 16 variations induced from the dihedral group of transforms (i.e. rotations, vertical and horizontal reflections) and antipodality (i.e. di- ametrically opposed points in the unitary sphere) into a single primitive. The key idea of our transform is to study the different dihedral elements as a group of symmetries within the high-dimensional manifold. We obtain the respective set of mirror-symmetry axes by means of a frequency analysis of the dihedral elements, and we use them to collapse the redundant variability through a modified symmetry distance. The experimental validation of our algorithm shows the effectiveness of our approach, which obtains competitive quality with a dictionary of as little as 32 atoms (reducing other methods{\textquoteright} dictionaries by at least a factor of 32) and further pushing the state-of-the-art with a 1024 atoms dictionary.</span></p>},
	url = {http://perezpellitero.github.io/},
	author = {E. Perez-Pellitero and Salvador, J. and Ruiz-Hidalgo, J. and Rosenhahn, B.}
}

@article{RED30,
  author    = {Xiao{-}Jiao Mao and
               Chunhua Shen and
               Yu{-}Bin Yang},
  title     = {Image Denoising Using Very Deep Fully Convolutional Encoder-Decoder
               Networks with Symmetric Skip Connections},
  journal   = {CoRR},
  volume    = {abs/1603.09056},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.09056},
  archivePrefix = {arXiv},
  eprint    = {1603.09056},
  timestamp = {Mon, 13 Aug 2018 16:46:31 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/MaoSY16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{TNRD, 
author={Y. {Chen} and T. {Pock}}, 
journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
title={Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration}, 
year={2017}, 
volume={39}, 
number={6}, 
pages={1256-1272}, 
abstract={Image restoration is a long-standing problem in low-level computer vision with many interesting applications. We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems. By embodying recent improvements in nonlinear diffusion models, we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters (i.e., linear filters and influence functions). In contrast to previous nonlinear diffusion models, all the parameters, including the filters and the influence functions, are simultaneously learned from training data through a loss based approach. We call this approach TNRD-Trainable Nonlinear Reaction Diffusion. The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force. We demonstrate its capabilities with three representative applications, Gaussian image denoising, single image super resolution and JPEG deblocking. Experiments show that our trained nonlinear diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for the tested applications. Our trained models preserve the structural simplicity of diffusion models and take only a small number of diffusion steps, thus are highly efficient. Moreover, they are also well-suited for parallel computation on GPUs, which makes the inference procedure extremely fast.}, 
keywords={Gaussian processes;graphics processing units;image denoising;image resolution;image restoration;learning (artificial intelligence);trainable nonlinear reaction diffusion;low-level computer vision;flexible learning framework;image restoration problems;dynamic nonlinear reaction diffusion model;time-dependent parameters;TNRD;JPEG deblocking;Gaussian image denoising;single-image super resolution;GPU;Image restoration;Computational modeling;Analytical models;Diffusion processes;Mathematical model;Image denoising;Nonlinear reaction diffusion;loss specific training;image denoising;image super resolution;JPEG deblocking}, 
doi={10.1109/TPAMI.2016.2596743}, 
ISSN={0162-8828}, 
month={June},}

@article{VDSR,
  author    = {Jiwon Kim and
               Jung Kwon Lee and
               Kyoung Mu Lee},
  title     = {Accurate Image Super-Resolution Using Very Deep Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1511.04587},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.04587},
  archivePrefix = {arXiv},
  eprint    = {1511.04587},
  timestamp = {Mon, 13 Aug 2018 16:46:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KimLL15b},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@INPROCEEDINGS{DRRN, 
author={Y. {Tai} and J. {Yang} and X. {Liu}}, 
booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Image Super-Resolution via Deep Recursive Residual Network}, 
year={2017}, 
volume={}, 
number={}, 
pages={2790-2798}, 
abstract={Recently, Convolutional Neural Network (CNN) based models have achieved great success in Single Image Super-Resolution (SISR). Owing to the strength of deep networks, these CNN models learn an effective nonlinear mapping from the low-resolution input image to the high-resolution target image, at the cost of requiring enormous parameters. This paper proposes a very deep CNN model (up to 52 convolutional layers) named Deep Recursive Residual Network (DRRN) that strives for deep yet concise networks. Specifically, residual learning is adopted, both in global and local manners, to mitigate the difficulty of training very deep networks, recursive learning is used to control the model parameters while increasing the depth. Extensive benchmark evaluation shows that DRRN significantly outperforms state of the art in SISR, while utilizing far fewer parameters. Code is available at https://github.com/tyshiwo/DRRN_CVPR17.}, 
keywords={convolution;image resolution;learning (artificial intelligence);recurrent neural nets;Deep Recursive Residual Network;Single Image Super-Resolution;deep CNN model;residual learning;recursive learning;Convolutional Neural Network;Image resolution;Training;Convolutional codes;Computational modeling;Convolution;Neural networks;Image restoration}, 
doi={10.1109/CVPR.2017.298}, 
ISSN={1063-6919}, 
month={July},}

@article{EDSR,
  author    = {Bee Lim and
               Sanghyun Son and
               Heewon Kim and
               Seungjun Nah and
               Kyoung Mu Lee},
  title     = {Enhanced Deep Residual Networks for Single Image Super-Resolution},
  journal   = {CoRR},
  volume    = {abs/1707.02921},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.02921},
  archivePrefix = {arXiv},
  eprint    = {1707.02921},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LimSKNL17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SRGAN,
  author    = {Christian Ledig and
               Lucas Theis and
               Ferenc Huszar and
               Jose Caballero and
               Andrew P. Aitken and
               Alykhan Tejani and
               Johannes Totz and
               Zehan Wang and
               Wenzhe Shi},
  title     = {Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial
               Network},
  journal   = {CoRR},
  volume    = {abs/1609.04802},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.04802},
  archivePrefix = {arXiv},
  eprint    = {1609.04802},
  timestamp = {Mon, 13 Aug 2018 16:48:38 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LedigTHCATTWS16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{CinCGAN,
  author    = {Yuan Yuan and
               Siyuan Liu and
               Jiawei Zhang and
               Yongbing Zhang and
               Chao Dong and
               Liang Lin},
  title     = {Unsupervised Image Super-Resolution using Cycle-in-Cycle Generative
               Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1809.00437},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.00437},
  archivePrefix = {arXiv},
  eprint    = {1809.00437},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-00437},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{SFT-GAN,
  author    = {Xintao Wang and
               Ke Yu and
               Chao Dong and
               Chen Change Loy},
  title     = {Recovering Realistic Texture in Image Super-resolution by Deep Spatial
               Feature Transform},
  journal   = {CoRR},
  volume    = {abs/1804.02815},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.02815},
  archivePrefix = {arXiv},
  eprint    = {1804.02815},
  timestamp = {Mon, 13 Aug 2018 16:49:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1804-02815},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{CycleGAN,
  author    = {Jun{-}Yan Zhu and
               Taesung Park and
               Phillip Isola and
               Alexei A. Efros},
  title     = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial
               Networks},
  journal   = {CoRR},
  volume    = {abs/1703.10593},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.10593},
  archivePrefix = {arXiv},
  eprint    = {1703.10593},
  timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhuPIE17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{VGG,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  crossref  = {DBLP:conf/iclr/2015},
  url       = {http://arxiv.org/abs/1409.1556},
  timestamp = {Fri, 29 Mar 2019 10:36:36 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  crossref  = {DBLP:conf/iclr/2015},
  url       = {http://arxiv.org/abs/1412.6980},
  timestamp = {Fri, 29 Mar 2019 10:36:36 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/KingmaB14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{grabber,
  author = {Bionus},
  title = {imgbrd-grabber},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Bionus/imgbrd-grabber}},
  commit = {ff54df85bd625d4810f9cbc1e5a97dffcb1d5d9b}
}
